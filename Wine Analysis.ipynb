{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding 4:\n",
    "\n",
    "**Group Members:**\n",
    "\n",
    "**Zubair Lalani (zubairl2)**\n",
    "\n",
    "**Adithya Swaminathan (adithya9)**\n",
    "\n",
    "## Setup\n",
    "Import necessary packages to perform the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Wine Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names taken from the \"wine.names\" file that came with the data\n",
    "\n",
    "col_names = [\n",
    "    \"class_num\",\n",
    "    \"alcohol\",\n",
    "    \"malic_acid\",\n",
    "    \"ash\",\n",
    "    \"alcalinity_of_ash\",\n",
    "    \"magnesium\",\n",
    "    \"total_phenols\",\n",
    "    \"flavanoids\",\n",
    "    \"nonflavanoid_phenols\",\n",
    "    \"proanthocyanins\",\n",
    "    \"color_intensity\",\n",
    "    \"hue\",\n",
    "    \"od280_od315_of_diluted_wines\",\n",
    "    \"proline\",\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"data/wine/wine.data\", header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_num</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280_od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_num  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
       "0          1    14.23        1.71  2.43               15.6        127   \n",
       "1          1    13.20        1.78  2.14               11.2        100   \n",
       "2          1    13.16        2.36  2.67               18.6        101   \n",
       "3          1    14.37        1.95  2.50               16.8        113   \n",
       "4          1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   color_intensity   hue  od280_od315_of_diluted_wines  proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values or duplicate rows. Seems no preprocessing is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_num                       0\n",
       "alcohol                         0\n",
       "malic_acid                      0\n",
       "ash                             0\n",
       "alcalinity_of_ash               0\n",
       "magnesium                       0\n",
       "total_phenols                   0\n",
       "flavanoids                      0\n",
       "nonflavanoid_phenols            0\n",
       "proanthocyanins                 0\n",
       "color_intensity                 0\n",
       "hue                             0\n",
       "od280_od315_of_diluted_wines    0\n",
       "proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, 0]\n",
    "X= df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check class balance and shapes of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_num\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "(178, 13) (178,)\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform stratified 70-30 train/test split wtih seed 598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=598,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_num\n",
      "2    50\n",
      "1    41\n",
      "3    33\n",
      "Name: count, dtype: int64\n",
      "class_num\n",
      "2    21\n",
      "1    18\n",
      "3    15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split with no stratification as well (as a sanity check since we get 100% accuracy in later sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_strat, X_test_no_strat, y_train_no_strat, y_test_no_strat = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=598,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_num\n",
      "2    45\n",
      "3    43\n",
      "1    36\n",
      "Name: count, dtype: int64\n",
      "class_num\n",
      "2    26\n",
      "1    23\n",
      "3     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_no_strat.value_counts())\n",
    "print(y_test_no_strat.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "**Using the training data fit three models: LDA, QDA and Multinomial (Logistic) regression.\n",
    "Note that here the response has three levels, so a binomial logistic is not applicable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuadraticDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuadraticDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>QuadraticDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "QuadraticDiscriminantAnalysis()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "qda_no_strat = QuadraticDiscriminantAnalysis()\n",
    "qda_no_strat.fit(X_train_no_strat, y_train_no_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "lda_no_strat = LinearDiscriminantAnalysis()\n",
    "lda_no_strat.fit(X_train_no_strat, y_train_no_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=2000, n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=2000, n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000, n_jobs=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(max_iter=2000, n_jobs=-1))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should do multinomial automatically by default\n",
    "# Scaling and increased max_iter to ensure convergence\n",
    "mlr = make_pipeline(\n",
    "    StandardScaler(with_mean=True),\n",
    "    LogisticRegression(max_iter=2000, solver=\"lbfgs\", n_jobs=-1)  # bump max_iter\n",
    ")\n",
    "\n",
    "mlr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "mlr_no_strat = make_pipeline(\n",
    "    StandardScaler(with_mean=True),\n",
    "    LogisticRegression(max_iter=2000, solver=\"lbfgs\", n_jobs=-1)  # bump max_iter\n",
    ")\n",
    "\n",
    "mlr_no_strat.fit(X_train_no_strat, y_train_no_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "**Report the accuracy for all methods on both training and testing data sets, and prepare\n",
    "confusion matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on training data\n",
    "\n",
    "qda_predictions_train = qda.predict(X_train)\n",
    "lda_predictions_train = lda.predict(X_train)\n",
    "mlr_predictions_train = mlr.predict(X_train)\n",
    "\n",
    "qda_accuracy_train = accuracy_score(y_train, qda_predictions_train)\n",
    "lda_accuracy_train = accuracy_score(y_train, lda_predictions_train)\n",
    "mlr_accuracy_train = accuracy_score(y_train, mlr_predictions_train)\n",
    "\n",
    "# Confusion matrix for training data\n",
    "cm_qda_train = confusion_matrix(y_train, qda_predictions_train)\n",
    "cm_lda_train = confusion_matrix(y_train, lda_predictions_train)\n",
    "cm_mlr_train = confusion_matrix(y_train, mlr_predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) QDA Accuracy:  1.0\n",
      "(train) LDA Accuracy:  1.0\n",
      "(train) MLR Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"(train) QDA Accuracy: \", qda_accuracy_train)\n",
    "print(\"(train) LDA Accuracy: \", lda_accuracy_train)\n",
    "print(\"(train) MLR Accuracy: \", mlr_accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) QDA Confusion Matrix\n",
      " [[41  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0  0 33]]\n",
      "(train) LDA Confusion Matrix\n",
      " [[41  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0  0 33]]\n",
      "(train) MLR Confusion Matrix\n",
      " [[41  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0  0 33]]\n"
     ]
    }
   ],
   "source": [
    "print(\"(train) QDA Confusion Matrix\\n\", cm_qda_train)\n",
    "print(\"(train) LDA Confusion Matrix\\n\", cm_lda_train)\n",
    "print(\"(train) MLR Confusion Matrix\\n\", cm_mlr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_predictions_test = qda.predict(X_test)\n",
    "lda_predictions_test = lda.predict(X_test)\n",
    "mlr_predictions_test = mlr.predict(X_test)\n",
    "\n",
    "qda_accuracy_test = accuracy_score(y_test, qda_predictions_test)\n",
    "lda_accuracy_test = accuracy_score(y_test, lda_predictions_test)\n",
    "mlr_accuracy_test = accuracy_score(y_test, mlr_predictions_test)\n",
    "\n",
    "# Confusion matrix for testing data\n",
    "cm_qda_test = confusion_matrix(y_test, qda_predictions_test)\n",
    "cm_lda_test = confusion_matrix(y_test, lda_predictions_test)\n",
    "cm_mlr_test = confusion_matrix(y_test, mlr_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test) QDA Accuracy:  1.0\n",
      "(test) LDA Accuracy:  1.0\n",
      "(test) MLR Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"(test) QDA Accuracy: \", qda_accuracy_test)\n",
    "print(\"(test) LDA Accuracy: \", lda_accuracy_test)\n",
    "print(\"(test) MLR Accuracy: \", mlr_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test) QDA Confusion Matrix\n",
      " [[18  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 15]]\n",
      "(test) LDA Confusion Matrix\n",
      " [[18  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 15]]\n",
      "(test) MLR Confusion Matrix\n",
      " [[18  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "print(\"(test) QDA Confusion Matrix\\n\", cm_qda_test)\n",
    "print(\"(test) LDA Confusion Matrix\\n\", cm_lda_test)\n",
    "print(\"(test) MLR Confusion Matrix\\n\", cm_mlr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, also tried without stratification to see if we still get 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) QDA (no strat) Accuracy:  1.0\n",
      "(train) LDA (no strat) Accuracy:  1.0\n",
      "(train) MLR (no strat) Accuracy:  1.0\n",
      "(test) QDA (no strat) Accuracy:  0.9814814814814815\n",
      "(test) LDA (no strat) Accuracy:  0.9629629629629629\n",
      "(test) MLR (no strat) Accuracy:  0.9629629629629629\n",
      "(test + no strat) QDA Confusion Matrix\n",
      " [[23  0  0]\n",
      " [ 1 25  0]\n",
      " [ 0  0  5]]\n",
      "(test + no strat) LDA Confusion Matrix\n",
      " [[23  0  0]\n",
      " [ 0 25  1]\n",
      " [ 0  1  4]]\n",
      "(test + no strat) MLR Confusion Matrix\n",
      " [[23  0  0]\n",
      " [ 0 25  1]\n",
      " [ 0  1  4]]\n"
     ]
    }
   ],
   "source": [
    "qda_predictions_no_strat_train = qda_no_strat.predict(X_train_no_strat)\n",
    "lda_predictions_no_strat_train = lda_no_strat.predict(X_train_no_strat)\n",
    "mlr_predictions_no_strat_train = mlr_no_strat.predict(X_train_no_strat)\n",
    "\n",
    "qda_accuracy_no_strat_train = accuracy_score(y_train_no_strat, qda_predictions_no_strat_train)\n",
    "lda_accuracy_no_strat_train = accuracy_score(y_train_no_strat, lda_predictions_no_strat_train)\n",
    "mlr_accuracy_no_strat_train = accuracy_score(y_train_no_strat, mlr_predictions_no_strat_train)\n",
    "\n",
    "print(\"(train) QDA (no strat) Accuracy: \", qda_accuracy_no_strat_train)\n",
    "print(\"(train) LDA (no strat) Accuracy: \", lda_accuracy_no_strat_train)\n",
    "print(\"(train) MLR (no strat) Accuracy: \", mlr_accuracy_no_strat_train)\n",
    "\n",
    "\n",
    "qda_predictions_no_strat_test = qda_no_strat.predict(X_test_no_strat)\n",
    "lda_predictions_no_strat_test = lda_no_strat.predict(X_test_no_strat)\n",
    "mlr_predictions_no_strat_test = mlr_no_strat.predict(X_test_no_strat)\n",
    "\n",
    "qda_accuracy_no_strat_test = accuracy_score(y_test_no_strat, qda_predictions_no_strat_test)\n",
    "lda_accuracy_no_strat_test = accuracy_score(y_test_no_strat, lda_predictions_no_strat_test)\n",
    "mlr_accuracy_no_strat_test = accuracy_score(y_test_no_strat, mlr_predictions_no_strat_test)\n",
    "\n",
    "print(\"(test) QDA (no strat) Accuracy: \", qda_accuracy_no_strat_test)\n",
    "print(\"(test) LDA (no strat) Accuracy: \", lda_accuracy_no_strat_test)\n",
    "print(\"(test) MLR (no strat) Accuracy: \", mlr_accuracy_no_strat_test)\n",
    "\n",
    "cm_qda_test = confusion_matrix(y_test_no_strat, qda_predictions_no_strat_test)\n",
    "cm_lda_test = confusion_matrix(y_test_no_strat, lda_predictions_no_strat_test)\n",
    "cm_mlr_test = confusion_matrix(y_test_no_strat, mlr_predictions_no_strat_test)\n",
    "\n",
    "print(\"(test + no strat) QDA Confusion Matrix\\n\", cm_qda_test)\n",
    "print(\"(test + no strat) LDA Confusion Matrix\\n\", cm_lda_test)\n",
    "print(\"(test + no strat) MLR Confusion Matrix\\n\", cm_mlr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "**Comment on the results. For example, discuss the following: Is there a model that seems\n",
    "to perform better overall? Which model misclassified more observations? Is there a class\n",
    "that performed better or worse (in terms of classification)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models performed quite perfectly because the data is already well separated. In fact, all 3 of the models were able to achieve 100% accuracy on both the training and testing data. As a result, the confusion matrices only have numbers on the diagonals with the values equal to the class distribution between the three classes. \n",
    "\n",
    "In order to sanity to check this result, we also tried performing the same steps without stratifying the dataset. In this case, we got relatively more \"normal\" results where we got 100% accuracy on the training set, but ~96%-98% accuracy on the testing dataset. Looking at the confusion matrices, the LDA + Logistic regression had 2 samples where it got confused between classes 2 and 3. The QDA model got confused between classes 1 and 2 once. With stratification, this confusion does not occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Digit Classification\n",
    "\n",
    "**Goal: goal is to compare the performance of SVM, Decision Trees and Boosting methods, such as\n",
    "AdaBoost, Gradient Boosting, XGBoost for correctly classifying all 10 digits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "**Perform 70-30 train/test split wtih seed 598**\n",
    "\n",
    "**Do not filter out certain labels from the data like we did in previous assignments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFOLDER = \"data/pen+based+recognition+of+handwritten+digits (1)/\"\n",
    "TRAIN_FILENAME = \"pendigits.tra\"\n",
    "TEST_FILENAME = \"pendigits.tes\"\n",
    "train_path = DATAFOLDER + TRAIN_FILENAME\n",
    "test_path = DATAFOLDER + TEST_FILENAME\n",
    "\n",
    "\n",
    "# Reading in the data\n",
    "train_data = np.loadtxt(train_path, delimiter=\",\")\n",
    "test_data = np.loadtxt(test_path, delimiter=\",\")\n",
    "\n",
    "X_train = train_data[:, 0:16]\n",
    "y_train = train_data[:, 16]\n",
    "X_test = test_data[:, 0:16]\n",
    "y_test = test_data[:, 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "**Fit a SVM classifier with a Gaussian kernel (also known as radial basis function) on\n",
    "the training data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='rbf', random_state=598)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred_svm_train, y_pred_svm_test = svm_classifier.predict(X_train), svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "**Fit a Decision Tree classifier on the training data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=598)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_pred_dt_train, y_pred_dt_test = dt_classifier.predict(X_train), dt_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "**Choose two boosting algorithms among AdaBoost, Gradient Boosting, or XGBoost\n",
    "and fit a classifier on the training data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_classifier = AdaBoostClassifier(random_state=598)\n",
    "ab_classifier.fit(X_train, y_train)\n",
    "y_pred_ab_train, y_pred_ab_test = ab_classifier.predict(X_train), ab_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoostingClassifier(random_state=598)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "y_pred_gb_train, y_pred_gb_test = gb_classifier.predict(X_train), gb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "**Report the accuracy for all classifiers fitted in (a), (b), (c) in both training and testing\n",
    "data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Train:  0.9966639978649586\n",
      "Test:  0.9817038307604345\n",
      "Decision Tree Classifier\n",
      "Train:  1.0\n",
      "Test:  0.9188107489994283\n",
      "Adaboost Classifier\n",
      "Train:  0.64758473445423\n",
      "Test:  0.6097770154373928\n",
      "Gradient Boost Classifier\n",
      "Train:  1.0\n",
      "Test:  0.9625500285877644\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Classifier\")\n",
    "print(\"Train: \", accuracy_score(y_train, y_pred_svm_train))\n",
    "print(\"Test: \", accuracy_score(y_test, y_pred_svm_test))\n",
    "\n",
    "print(\"Decision Tree Classifier\")\n",
    "print(\"Train: \", accuracy_score(y_train, y_pred_dt_train))\n",
    "print(\"Test: \", accuracy_score(y_test, y_pred_dt_test))\n",
    "\n",
    "print(\"Adaboost Classifier\")\n",
    "print(\"Train: \", accuracy_score(y_train, y_pred_ab_train))\n",
    "print(\"Test: \", accuracy_score(y_test, y_pred_ab_test))\n",
    "\n",
    "print(\"Gradient Boost Classifier\")\n",
    "print(\"Train: \", accuracy_score(y_train, y_pred_gb_train))\n",
    "print(\"Test: \", accuracy_score(y_test, y_pred_gb_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "**Report the confusion matrix for the test predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_svm_test = confusion_matrix(y_test, y_pred_svm_test)\n",
    "cm_dt_test = confusion_matrix(y_test, y_pred_dt_test)\n",
    "cm_ab_test = confusion_matrix(y_test, y_pred_ab_test)\n",
    "cm_gb_test = confusion_matrix(y_test, y_pred_gb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Confusion Matrix:\n",
      " [[353   0   0   0   0   0   0   0  10   0]\n",
      " [  0 350  13   0   1   0   0   0   0   0]\n",
      " [  0   2 362   0   0   0   0   0   0   0]\n",
      " [  0   1   0 333   0   0   0   0   0   2]\n",
      " [  0   0   0   0 359   4   1   0   0   0]\n",
      " [  0   0   0   4   0 329   0   0   0   2]\n",
      " [  0   0   0   0   0   0 336   0   0   0]\n",
      " [  0  12   1   0   0   0   0 347   0   4]\n",
      " [  0   0   0   0   0   1   0   0 335   0]\n",
      " [  0   2   0   0   0   0   0   3   1 330]]\n",
      "DecisionTree Confusion Matrix:\n",
      " [[344   0   1   0   1   0   1   1  13   2]\n",
      " [  0 318  41   1   1   1   1   1   0   0]\n",
      " [  0  10 351   0   0   0   1   2   0   0]\n",
      " [  1  11   2 314   0   1   0   3   0   4]\n",
      " [  0   2   0   1 354   2   4   1   0   0]\n",
      " [  0   3   0  25   2 287   0   1   5  12]\n",
      " [  4   4   1   0   7   4 315   0   1   0]\n",
      " [  0  39   4   8   0   0   1 308   4   0]\n",
      " [  5   1   0   1   5   3   6   4 311   0]\n",
      " [  0   6   0   4   5   3   0   3   3 312]]\n",
      "Adaboost Confusion Matrix:\n",
      " [[337   0   1   0   0   0  23   0   2   0]\n",
      " [  0 212 138   5   4   0   2   0   0   3]\n",
      " [  0   8 334   1   0   0  13   8   0   0]\n",
      " [  0   2  60 245   0  19   9   0   0   1]\n",
      " [  1   9   3   0 325   0  19   0   0   7]\n",
      " [167  12   0 119   2  11  15   0   1   8]\n",
      " [  0   0   0   8   0   0 308   5  13   2]\n",
      " [  0  31  12   2   0   0   9 270  18  22]\n",
      " [266   0  10   0   0   0  13  28  19   0]\n",
      " [  1  24   9 168  12  30  20   0   0  72]]\n",
      "Gradient Boost Confusion Matrix:\n",
      " [[343   0   0   0   0   0   0   0  20   0]\n",
      " [  0 340  22   0   1   1   0   0   0   0]\n",
      " [  0   3 360   0   0   0   0   1   0   0]\n",
      " [  0   3   0 331   0   0   0   1   0   1]\n",
      " [  0   1   0   0 363   0   0   0   0   0]\n",
      " [  0   0   0   5   0 311   0   0   4  15]\n",
      " [  0   0   0   0   0   1 334   0   1   0]\n",
      " [  0  19   3   0   0   0   0 327   0  15]\n",
      " [  0   0   0   0   0   0   0   0 336   0]\n",
      " [  0   6   0   6   0   0   0   1   1 322]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Confusion Matrix:\\n\", cm_svm_test)\n",
    "print(\"DecisionTree Confusion Matrix:\\n\", cm_dt_test)\n",
    "print(\"Adaboost Confusion Matrix:\\n\", cm_ab_test)\n",
    "print(\"Gradient Boost Confusion Matrix:\\n\", cm_gb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F\n",
    "\n",
    "**Comment on the results. Which are the digits that seem to be most commonly confused?\n",
    "Did you have any overfitting issues with any of the approaches?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen through our results, it seems that the models that performed the best on the test data was the Gradient Boosting classifier and the SVM classifier. Adaboost performed poorly on both train and test predictions. The digits that saw the most issues with accuracy across all classifier models were 0, 5, and 7. 0 had a lot of predictions predict it as the digit 8. Similarly, 5 was confused with 3 and 7 with 1. Adaboost obviously did not perform well on these digits either (as seen from the results), but it additionally had issues with 1, 3, and 8. In terms of overfitting, not much issues were encountered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (coding4-venv",
   "language": "python",
   "name": "coding4-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
